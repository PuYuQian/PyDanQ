{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "#from tensorboardX import SummaryWriter\n",
    "from sklearn.metrics import roc_auc_score,roc_curve,auc,average_precision_score,precision_recall_curve\n",
    "torch.manual_seed(1337)\n",
    "np.random.seed(1337)\n",
    "torch.cuda.manual_seed(1337)\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('starting loading the data')\n",
    "np_test_data = scipy.io.loadmat('test.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_Pol2 = np_test_data['testdata'][:, [332,354,408,431,432,433,451,453,455,457,459,461,463]].sum(axis=1) > 0\n",
    "\n",
    "X_test_NRSF = np_test_data['testxdata'][y_test_Pol2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_NRSF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_NRSF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=0\n",
    "true_list=[]\n",
    "for i in range(len(y_test_NRSF)):\n",
    "    if(y_test_NRSF[i]==True):\n",
    "        true_list.append(i)\n",
    "        num+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pos_train = np_test_data['testdata'].sum()\n",
    "print('Sparsity: %0.4f' % (1 - 1.0 * total_pos_train / np.prod(np_test_data['testdata'].shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('compling the network')\n",
    "class DanQ(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(DanQ, self).__init__()\n",
    "        self.Conv1 = nn.Conv1d(in_channels=4, out_channels=320, kernel_size=13)\n",
    "        #nn.init.uniform_(self.Conv1.weight, -0.05, 0.05)\n",
    "        self.Maxpool = nn.MaxPool1d(kernel_size=13, stride=6)\n",
    "        self.Drop1 = nn.Dropout(p=0.2)\n",
    "        self.BiLSTM = nn.LSTM(input_size=320, hidden_size=320, num_layers=2,\n",
    "                                 batch_first=True,\n",
    "                                 dropout=0.5,\n",
    "                                 bidirectional=True)\n",
    "        self.Linear1 = nn.Linear(163*640, 925)\n",
    "        self.Linear2 = nn.Linear(925, 919)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.Conv1(input)\n",
    "        x1 = F.relu(x)\n",
    "        x = self.Maxpool(x1)\n",
    "        x = self.Drop1(x)\n",
    "        x_x = torch.transpose(x, 1, 2)\n",
    "        x, (h_n,h_c) = self.BiLSTM(x_x)\n",
    "        #x, h_n = self.BiGRU(x_x)\n",
    "        x = x.contiguous().view(-1, 163*640)\n",
    "        x = self.Linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.Linear2(x)\n",
    "        #x = torch.sigmoid(x)\n",
    "        return x1,x\n",
    "\n",
    "danq = DanQ()\n",
    "danq.load_state_dict(torch.load('model/model0512_2/danq_net_params_4.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs = np.zeros((320, 4, 13))\n",
    "nsites = np.zeros(320)\n",
    "danq.eval()\n",
    "for i in range(0, len(X_test_NRSF), 100):\n",
    "    x = X_test_NRSF[i:i+100]\n",
    "    x_tensor = torch.FloatTensor(x)\n",
    "    #print(seq.shape)\n",
    "    conv_output, _ = danq(x_tensor)\n",
    "    max_inds = np.argmax(conv_output.cpu().detach().numpy().data, axis=2)\n",
    "    max_acts = np.max(conv_output.cpu().detach().numpy().data, axis=2)\n",
    "    #print(max_inds.shape)\n",
    "    #print(max_acts.shape)\n",
    "    for m in range(320):\n",
    "        for n in range(len(x)):\n",
    "            if max_acts[n, m] > 0:\n",
    "                nsites[m] += 1\n",
    "                motifs[m] += x[n, :, max_inds[n, m]:max_inds[n, m]+13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_output.cpu().detach().numpy().data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=0\n",
    "for m in range(320):\n",
    "        for n in range(len(x)):\n",
    "            if max_acts[n, m] < 0:\n",
    "                num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs = np.transpose(motifs,(0, 2, 1))\n",
    "print(motifs.shape)\n",
    "print('Making motifs')\n",
    "\n",
    "motifs = motifs[:, :, [0, 2, 1, 3]]\n",
    "\n",
    "motifs_file = open('motifs_Pol2.txt', 'w')\n",
    "motifs_file.write('MEME version 5.0.5\\n\\n'\n",
    "                  'ALPHABET= ACGT\\n\\n'\n",
    "                  'strands: + -\\n\\n'\n",
    "                  'Background letter frequencies (from uniform background):\\n'\n",
    "                  'A 0.25000 C 0.25000 G 0.25000 T 0.25000\\n\\n')\n",
    "\n",
    "for m in range(320):\n",
    "    if nsites[m] == 0:\n",
    "        continue\n",
    "    motifs_file.write('MOTIF M%i O%i\\n' % (m, m))\n",
    "    motifs_file.write(\"letter-probability matrix: alength= 4 w= %i nsites= %i E= 1337.0e-6\\n\" % (13, nsites[m]))\n",
    "    for j in range(13):\n",
    "        motifs_file.write(\"%f %f %f %f\\n\" % tuple(1.0 * motifs[m, j, 0:4] / np.sum(motifs[m, j, 0:4])))\n",
    "    motifs_file.write('\\n')\n",
    "\n",
    "motifs_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs = np.transpose(motifs,(0, 2, 1))\n",
    "print(motifs.shape)\n",
    "print('Making motifs')\n",
    "\n",
    "motifs = motifs[:, :, [0, 2, 1, 3]]\n",
    "\n",
    "motifs_file = open('motifs_Pol2_heatmap.txt', 'w')\n",
    "for m in range(320):\n",
    "    if nsites[m] == 0:\n",
    "        continue\n",
    "    for j in range(13):\n",
    "        p = 1.0 * motifs[m, j, 0:4] / np.sum(motifs[m, j, 0:4])\n",
    "        motifs_file.write(\"%f %f %f %f\\n\" % tuple(1.0 * motifs[m, j, 0:4] / np.sum(motifs[m, j, 0:4])))\n",
    "    motifs_file.write('\\n')\n",
    "\n",
    "motifs_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
